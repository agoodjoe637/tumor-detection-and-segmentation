{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac85d867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam 369 hasta bulundu.\n",
      "295 hasta egitim icin, 74 hasta validasyon için ayrildi.\n",
      "\n",
      "--- Eğitim Veri Seti Yükleniyor ---\n",
      "Veri seti taraniyor ve dosyalar dogrulaniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hastalar Taranıyor: 100%|██████████| 295/295 [00:00<00:00, 3778.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dogrulama tamamlandi. Toplam 295 adet gecerli hasta bulundu.\n",
      "\n",
      "--- Validasyon Veri Seti Yukleniyor ---\n",
      "Veri seti taraniyor ve dosyalar dogrulaniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hastalar Taranıyor: 100%|██████████| 74/74 [00:00<00:00, 3449.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dogrulama tamamlandi. Toplam 74 adet gecerli hasta bulundu.\n",
      "\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Yeni bir model oluşturuldu. Egitime sifirdan baslaniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 [Eğitim]:   5%|▌         | 143/2858 [02:15<37:29,  1.21it/s] "
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split \n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels), nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x): return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2), DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "    def forward(self, x): return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "    def forward(self, x): return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128); self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512); self.down4 = Down(512, 1024)\n",
    "        self.up1 = Up(1024, 512); self.up2 = Up(512, 256)\n",
    "        self.up3 = Up(256, 128); self.up4 = Up(128, 64)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x); x2 = self.down1(x1); x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3); x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4); x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2); x = self.up4(x, x1)\n",
    "        return self.outc(x)\n",
    "\n",
    "\n",
    "\n",
    "class BratsDataset(Dataset):\n",
    "    def __init__(self, patient_dirs):\n",
    "        super().__init__()\n",
    "        self.patient_dirs = patient_dirs\n",
    "        self.image_paths = []\n",
    "        self.mask_paths = []\n",
    "        self.num_slices_per_scan = 155\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        print(\"Veri seti taraniyor ve dosyalar dogrulaniyor...\")\n",
    "        \n",
    "        for patient_dir in tqdm(self.patient_dirs, desc=\"Hastalar Taranıyor\"):\n",
    "            \n",
    "            flair_files = list(patient_dir.glob('*_flair.nii'))\n",
    "            seg_files = list(patient_dir.glob('*_seg.nii')) + list(patient_dir.glob('*Segm.nii'))\n",
    "\n",
    "            \n",
    "            if len(flair_files) == 1 and len(seg_files) == 1:\n",
    "                self.image_paths.append(flair_files[0])\n",
    "                self.mask_paths.append(seg_files[0])\n",
    "\n",
    "        print(f\"Dogrulama tamamlandi. Toplam {len(self.image_paths)} adet gecerli hasta bulundu.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.image_paths) * self.num_slices_per_scan\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patient_idx = idx // self.num_slices_per_scan\n",
    "        slice_idx = idx % self.num_slices_per_scan\n",
    "\n",
    "        image_path = self.image_paths[patient_idx]\n",
    "        mask_path = self.mask_paths[patient_idx] \n",
    "\n",
    "        image_nii = nib.load(image_path); mask_nii = nib.load(mask_path)\n",
    "        image_data_3d = image_nii.get_fdata(); mask_data_3d = mask_nii.get_fdata()\n",
    "        \n",
    "        image_slice = image_data_3d[:, :, slice_idx]\n",
    "        mask_slice = mask_data_3d[:, :, slice_idx]\n",
    "        \n",
    "        image_tensor = torch.from_numpy(image_slice.copy()).float().unsqueeze(0)\n",
    "        mask_tensor = torch.from_numpy(mask_slice.copy()).long()\n",
    "        \n",
    "        mask_tensor[mask_tensor == 4] = 3\n",
    "        \n",
    "        return {'image': image_tensor, 'mask': mask_tensor}\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    \n",
    "    data_folder = Path('./data/MICCAI_BraTS2020_TrainingData/')\n",
    "    \n",
    "    all_patient_dirs = [d for d in data_folder.iterdir() if d.is_dir()]\n",
    "\n",
    "    \n",
    "    train_dirs, val_dirs = train_test_split(all_patient_dirs, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(f\"Toplam {len(all_patient_dirs)} hasta bulundu.\")\n",
    "    print(f\"{len(train_dirs)} hasta egitim icin, {len(val_dirs)} hasta validasyon için ayrildi.\")\n",
    "\n",
    "    \n",
    "    print(\"\\n--- Eğitim Veri Seti Yükleniyor ---\")\n",
    "    train_dataset = BratsDataset(patient_dirs=train_dirs)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "    \n",
    "    print(\"\\n--- Validasyon Veri Seti Yukleniyor ---\")\n",
    "    validation_dataset = BratsDataset(patient_dirs=val_dirs)\n",
    "    validation_loader = DataLoader(validation_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "    \n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'\\nUsing device: {device}')\n",
    "    \n",
    "    model = UNet(n_channels=1, n_classes=4).to(device)\n",
    "    \n",
    "    \n",
    "    print(\"\\nYeni bir model oluşturuldu. Egitime sifirdan baslaniyor...\")\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    num_epochs = 5\n",
    "\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        model.train() \n",
    "        epoch_train_loss = 0\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} [Eğitim]\"):\n",
    "            images = batch['image'].to(device=device)\n",
    "            true_masks = batch['mask'].to(device=device)\n",
    "        \n",
    "            predicted_masks = model(images)\n",
    "            loss = criterion(predicted_masks, true_masks)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_train_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = epoch_train_loss / len(train_loader)\n",
    "\n",
    "        \n",
    "        model.eval() \n",
    "        epoch_val_loss = 0\n",
    "        with torch.no_grad(): \n",
    "            for batch in tqdm(validation_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} [Doğrulama]\"):\n",
    "                images = batch['image'].to(device=device)\n",
    "                true_masks = batch['mask'].to(device=device)\n",
    "                \n",
    "                predicted_masks = model(images)\n",
    "                loss = criterion(predicted_masks, true_masks)\n",
    "                \n",
    "                epoch_val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = epoch_val_loss / len(validation_loader)\n",
    "\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} -> \"\n",
    "              f\"Ortalama Egitim Kaybi (Train Loss): {avg_train_loss:.4f}, \"\n",
    "              f\"Ortalama Dogrulama Kaybi (Validation Loss): {avg_val_loss:.4f}\")\n",
    "\n",
    "        torch.save(model.state_dict(), f\"model_epoch_{epoch+1}.pth\")\n",
    "        print(f\"Model 'model_epoch_{epoch+1}.pth' olarak kaydedildi.\\n\")\n",
    "\n",
    "    print(\"Training and validation finished!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"\\nEgitim sirasinda bir hata olustu:\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0334ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelin mevcut durumu model_checkpoint.pth dosyasina kaydedildi!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MODEL_PATH = \"model_checkpoint.pth\"\n",
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "\n",
    "print(f\"Modelin mevcut durumu {MODEL_PATH} dosyasina kaydedildi!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medikal-proje-env (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
